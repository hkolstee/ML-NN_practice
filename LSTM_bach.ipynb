{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do: <br/>Grid search on best model paramaters / criterions / optimizers / learning rates / window sizes <br/> Use new data representation (from unpublished thesis)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Create train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load voices\n",
    "voices = np.loadtxt(\"F.txt\", dtype=np.int8)\n",
    "print(voices)\n",
    "\n",
    "# Delete starting silence\n",
    "voices = np.delete(voices, slice(8), axis=0)\n",
    "print(voices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split voices\n",
    "voice_one = voices[:,0]\n",
    "voice_two = voices[:,1]\n",
    "voice_three = voices[:,2]\n",
    "voice_four = voices[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the amount of unique notes in the voices\n",
    "# This is important for the model input dimensions when creating the model\n",
    "voice_one_unique = set(voice_one)\n",
    "voice_two_unique = set(voice_two)\n",
    "voice_three_unique = set(voice_three)\n",
    "voice_four_unique = set(voice_four)\n",
    "print(\"{} unique notes are found in voice one\".format(len(voice_one_unique)))\n",
    "print(\"{} unique notes are found in voice two\".format(len(voice_two_unique)))\n",
    "print(\"{} unique notes are found in voice three\".format(len(voice_three_unique)))\n",
    "print(\"{} unique notes are found in voice four\".format(len(voice_four_unique)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to create train test data\n",
    "def train_test(voice):\n",
    "\n",
    "    train = []\n",
    "    test = []\n",
    "    \n",
    "    # initialize how far in the past you want to look\n",
    "    memory_window = 20\n",
    "    \n",
    "    # get a list of all the unique notes in the voice\n",
    "    voice_set = set(voice)\n",
    "    distribution_notes = list(voice_set)\n",
    "\n",
    "    for i in range(len(voice) - (memory_window+1)):\n",
    "        # the train data is a time-window of voices\n",
    "        train.append(voice[i:i+ memory_window])\n",
    "        \n",
    "        # the test data is a probability one-hot encoded vector\n",
    "        # create empty probability vector\n",
    "        probability_vector = [0] * len(distribution_notes)\n",
    "        # get the next note and find its index in the distribution\n",
    "        next_note = voice[i+ memory_window + 1]\n",
    "        idx = distribution_notes.index(next_note)\n",
    "        # change the value at that position to 1 in the empty probability vector\n",
    "        # and add it to the test set\n",
    "        probability_vector[idx] = 1\n",
    "        test.append(probability_vector)\n",
    "\n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test data\n",
    "train, test = train_test(voice_one)\n",
    "print(np.shape(train), np.shape(test))\n",
    "print(train, test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Create data representation similar to unpublished thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_offset(voice):\n",
    "    \n",
    "    # get the max and min values of a voice\n",
    "    voice_max = np.amax(voice)\n",
    "    # sort the array and keep only the unique values, because '0' is not a chord but a break,\n",
    "    # so it shouldnt be the 'min value'.\n",
    "    voice_sort = np.sort(voice)\n",
    "    voice_sort = np.unique(voice_sort)\n",
    "    voice_min = voice_sort[1]\n",
    "    \n",
    "    # calculate voice offset as: 2log2(voice_max) - 2log2(voice_min)/2 - 2log2(voice_max)\n",
    "    voice_offset = (2 * math.log2(voice_max) - 2 * math.log2(voice_min))/2\n",
    "    voice_offset = voice_offset - (2* math.log2(voice_max))\n",
    "    \n",
    "    return voice_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chroma_circle(note):\n",
    "    theta = (2*math.pi*(note % 12)/12)\n",
    "    \n",
    "    # r is the scaling set to 1\n",
    "    r = 1   \n",
    "    x = math.cos(theta) * r\n",
    "    y = math.sin(theta) * r\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fifth_circle(note):\n",
    "    theta = (2*math.pi*(7*note % 12)/12)\n",
    "    \n",
    "    # r is the scaling set to 1\n",
    "    r = 1   \n",
    "    x = math.cos(theta) * r\n",
    "    y = math.sin(theta) * r\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voice_representation(voice, data):\n",
    "    \n",
    "    # list to save values\n",
    "    new_representation = []\n",
    "    \n",
    "    # calculate offset of voice\n",
    "    offset = cal_offset(voice)\n",
    "    \n",
    "    try:\n",
    "        for training_data in data:\n",
    "            # vector to save the new representation\n",
    "            vector = []\n",
    "            for note in training_data:\n",
    "                # if the note is 0, it's a break and should be noted as [0 0 0 0 0] ??\n",
    "                if note == 0:\n",
    "                    vector.append(0)\n",
    "                    vector.append(0)\n",
    "                    vector.append(0)\n",
    "                    vector.append(0)\n",
    "                    vector.append(0)\n",
    "                    continue\n",
    "\n",
    "                # normalized frequency = 2log2(note)+offset(voice)\n",
    "                voice_norm = 2*math.log2(note) + offset\n",
    "\n",
    "                x_chroma, y_chroma = chroma_circle(note)\n",
    "                x_fifth, y_fifth = fifth_circle(note)\n",
    "\n",
    "                vector.append(voice_norm)\n",
    "                vector.append(x_chroma)\n",
    "                vector.append(y_chroma)\n",
    "                vector.append(x_fifth)\n",
    "                vector.append(y_fifth)\n",
    "    except:\n",
    "            # vector to save the new representation\n",
    "            vector = []\n",
    "            for note in data:\n",
    "                # if the note is 0, it's a break and should be noted as [0 0 0 0 0] ??\n",
    "                if note == 0:\n",
    "                    vector.append(0)\n",
    "                    vector.append(0)\n",
    "                    vector.append(0)\n",
    "                    vector.append(0)\n",
    "                    vector.append(0)\n",
    "                    continue\n",
    "\n",
    "                # normalized frequency = 2log2(note)+offset(voice)\n",
    "                voice_norm = 2*math.log2(note) + offset\n",
    "\n",
    "                x_chroma, y_chroma = chroma_circle(note)\n",
    "                x_fifth, y_fifth = fifth_circle(note)\n",
    "\n",
    "                vector.append(voice_norm)\n",
    "                vector.append(x_chroma)\n",
    "                vector.append(y_chroma)\n",
    "                vector.append(x_fifth)\n",
    "                vector.append(y_fifth)\n",
    "    new_representation.append(vector)\n",
    "        \n",
    "    return np.array(new_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_one_train_rep = voice_representation(voice_one, train)\n",
    "print(voice_one_train_rep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Create and train the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTM_model, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        print(\"LSTM initialized with {} input size, {} hidden layer size, {} number of LSTM layers, and an output size of {}\".format(input_size, hidden_size, num_layers, output_size))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        h0 = torch.zeros(self.num_layers, input.size(0), self.hidden_size) \n",
    "        c0 = torch.zeros(self.num_layers, input.size(0), self.hidden_size)\n",
    "        \n",
    "        out, (hn, cn) = self.lstm(input, (h0, c0)) \n",
    "        out = self.linear(out)  \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "input_size = np.shape(train)[1]\n",
    "hidden_size = 32\n",
    "num_layers = 1\n",
    "output_size = np.shape(test)[1]\n",
    "LSTM_model = LSTM_model(input_size, hidden_size, num_layers, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training loop\n",
    "def training(LSTM_model, n_epochs, optimizer, criterion, train, test):\n",
    "    for i in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        predictions = LSTM_model(train)\n",
    "        # squeeze prediction because of broadcasting error (have to test if this even helps)\n",
    "        loss = criterion(predictions, test)\n",
    "        loss.backward()\n",
    "\n",
    "        if (i % 25 == 0):\n",
    "            print(\"Epoch:\", i, \"  Loss:\", loss.item())\n",
    "     \n",
    "        optimizer.step()\n",
    "\n",
    "    return (predictions.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(LSTM_model.parameters(), lr=0.08)\n",
    "\n",
    "# print(np.shape(train), np.shape(test))\n",
    "\n",
    "train_tensor = torch.FloatTensor(train).unsqueeze(0)\n",
    "test_tensor = torch.FloatTensor(test).unsqueeze(0)\n",
    "\n",
    "print(train_tensor.size())\n",
    "print(test_tensor.size())\n",
    "\n",
    "training(LSTM_model, 300, optimizer, criterion, train_tensor, test_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
